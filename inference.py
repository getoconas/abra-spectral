import torch
import numpy as np
import librosa
import soundfile as sf
import os
import torch.nn.functional as F

# Importamos tus m√≥dulos
from src.core import audio
from src.models import unet

# --- CONFIGURACI√ìN ---
# Ruta del cerebro que acabas de entrenar
MODELO_ENTRENADO = os.path.join("data", "output", "abra_model_generalist.pth")

# ¬°IMPORTANTE! Cambia esto por una canci√≥n NUEVA (que la IA no haya estudiado)
# Por ejemplo, la de Foster the People que usaste al principio
CANCION_NUEVA = "05 - Forrest Gump.mp3" 

DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

def separar_con_ia():
  print(f"üöÄ Iniciando inferencia en {DEVICE} con modelo Lite...")

  # 1. Cargar el modelo (La arquitectura debe ser IGUAL a la del entrenamiento)
  # Como usamos la versi√≥n Lite en unet.py, al instanciarla aqu√≠ ya viene con los 16 canales
  print("üß† Cargando cerebro...")
  try:
    red = unet.AbraUNet(n_channels=1, n_classes=1).to(DEVICE)
    red.load_state_dict(torch.load(MODELO_ENTRENADO, map_location=DEVICE))
    red.eval() # Modo evaluaci√≥n (apaga el aprendizaje y congela las neuronas)
  except Exception as e:
    print(f"‚ùå Error cargando el modelo: {e}")
    return

  # 2. Cargar la canci√≥n nueva
  ruta_input = os.path.join("data", "input", CANCION_NUEVA)
  if not os.path.exists(ruta_input):
    print(f"‚ùå No encuentro la canci√≥n: {ruta_input}")
    return

  print(f"üéß Cargando audio: {CANCION_NUEVA}...")
  # Cargamos 30 segundos para probar r√°pido (puedes poner None para toda la canci√≥n)
  y, sr = audio.cargar_audio(ruta_input, duration=30, mono=True)
  
  # 3. Preprocesamiento (STFT)
  # Usamos hop_length=512 igual que en el entrenamiento final
  D = librosa.stft(y, hop_length=512)
  S_mag, S_phase = librosa.magphase(D) # Separamos Magnitud (Imagen) y Fase (Sonido)

  # Convertir a Tensor
  tensor_input = torch.tensor(S_mag).unsqueeze(0).unsqueeze(0).to(DEVICE)

  # 4. La IA hace su magia
  print("üîÆ Separando bater√≠a...")
  with torch.no_grad():
    mask_pred = red(tensor_input)
  
  # 5. Reconstrucci√≥n
  # A veces la IA devuelve un tama√±o ligeramente distinto, ajustamos con interpolaci√≥n
  mask_final = F.interpolate(
    mask_pred, 
    size=(S_mag.shape[0], S_mag.shape[1]), 
    mode='bilinear', 
    align_corners=False
  ).squeeze().cpu().numpy()

  # --- üõ†Ô∏è NUEVO: PUERTA DE RUIDO Y LIMPIEZA ---
  # Cualquier valor de la m√°scara menor al umbral se silencia (vuelve a 0)
  # Prob√° con 0.1 o 0.15 para empezar. Si es muy alto, perd√©s platillos.
  umbral = 0.12 
  mask_final[mask_final < umbral] = 0.0

  # Aplicamos un "Contraste" (opcional): los valores altos se refuerzan
  # Esto ayuda a que el golpe de bater√≠a sea m√°s seco y definido
  mask_final = np.power(mask_final, 1.2)
  # --------------------------------------------

  # Aplicamos la m√°scara a la magnitud original
  bateria_espectro = S_mag * mask_final
  
  # Reconstruimos el audio usando la fase original (ISTFT)
  y_bateria = librosa.istft(bateria_espectro * S_phase, hop_length=512)

  # Cortamos frecuencias por debajo de 30Hz que suelen ser puro ruido subs√≥nico
  #y_bateria = librosa.effects.preemphasis(y_bateria)

  # 6. Guardar
  ruta_salida = os.path.join("data", "output", "resultado_ia_drums.wav")
  sf.write(ruta_salida, y_bateria, sr)
  print(f"‚úÖ ¬°√âxito! Escucha el resultado en: {ruta_salida}")

if __name__ == "__main__":
  separar_con_ia()